{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_finetuning_stop_clickbait.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KMTn9bhktYps",
        "cDzVIeTqtgHF",
        "HKcowprstl0r",
        "9Czy69V6tjnB",
        "HyRKSP2zwYyo",
        "dexXAe2b0LQl",
        "m4mlvS-W4TDx",
        "Y-C-yuTZILRE"
      ],
      "mount_file_id": "10NEI-NCy4z9AsBLZtdjysK2uh63kEZJC",
      "authorship_tag": "ABX9TyNNpvyLYyvM8fq235EiMb1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul94jh/MSC-Research/blob/main/bert_finetuning_stop_clickbait.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMTn9bhktYps"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7pZ99IQqhKo",
        "outputId": "806ea794-be78-4495-e8af-4f3bbe570e59"
      },
      "source": [
        "#Check GPU, if assigned k8 then factory reset couple of times until we get Tesla GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul  4 10:23:40 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73DTOjAUnKJO",
        "outputId": "242c90d3-c0c9-4252-a3f2-d72d72667907"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.3MB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 46.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 52.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.2MB 83kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/tensorflow-model-optimization/\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 215kB 57.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 686kB 40.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 40.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDzVIeTqtgHF"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q_MKLxE-7yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba5da38-4633-453e-d0c5-e7bd3b10e918"
      },
      "source": [
        "import os, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import shutil\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from official.nlp import optimization  # to create AdamW optmizer\n",
        "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "import sys\n",
        "\n",
        "#Import custom script\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/clcikbait_detection/scripts')\n",
        "from tf_dataset_helpers import read_tfrec_data\n",
        "import model_helpers as mh\n",
        "import visualization_helpers as vh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RE9WE8LtUhd",
        "outputId": "ee65103b-0db1-434c-b6a3-7b10414cb6e7"
      },
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version:  2.5.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKcowprstl0r"
      },
      "source": [
        "#Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTNn3LRp7DfR"
      },
      "source": [
        "#Bert configs\n",
        "bert_model_name = 'bert_en_uncased_L-12_H-768_A-12' \n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4'\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9DLhbQrtnGd"
      },
      "source": [
        "tfrecFiles_path = '/content/drive/MyDrive/Colab Notebooks/clcikbait_detection/dataset/Stop_clickbait/tfrec_data/'\n",
        "model_root_path = '/content/drive/MyDrive/Colab Notebooks/clcikbait_detection/dataset/Stop_clickbait/saved_models'\n",
        "saved_model_name = f'stop_clickbait_finetuned_{bert_model_name}'\n",
        "saved_model_path = os.path.join(model_root_path, saved_model_name )\n",
        "checkpoint_root_path = '/content/drive/MyDrive/Colab Notebooks/clcikbait_detection/dataset/Stop_clickbait/saved_models/checkpoints'\n",
        "model_checkpoint_path = os.path.join(checkpoint_root_path, 'my_checkpoint' )\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32  \n",
        "# Label categories\n",
        "label_list = [0,1]\n",
        "# maximum length of (token) input sequences\n",
        "max_seq_len = 128\n",
        "init_lr = 2e-5\n",
        "\n",
        "epochs = 2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSjQAbWngdd6",
        "outputId": "1dd35a61-e2f0-4cfb-9898-bcf999e69732"
      },
      "source": [
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print('BERT model selected           :', tfhub_handle_encoder)\n",
        "print('Preprocessing model auto-selected:', tfhub_handle_preprocess)\n",
        "\n",
        "bert_layer = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='bert_encoder')\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "bert_tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
            "Preprocessing model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Czy69V6tjnB"
      },
      "source": [
        "#Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e62N59Ttk60",
        "cellView": "form"
      },
      "source": [
        "#@title \"Utilities [RUN ME]\"\n",
        "def read_tfrecord(example):\n",
        "    features = {\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
        "        \"text\": tf.io.FixedLenFeature([], tf.string),\n",
        "        \"label\": tf.io.FixedLenFeature([], tf.string)  # one bytestring\n",
        "    }\n",
        "    # decode the TFRecord\n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    \n",
        "    \n",
        "    class_num = example['class']\n",
        "    text = example['text']\n",
        "    label  = example['label']\n",
        "    return text, class_num, label\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  return dataset\n",
        "\n",
        "def get_batched_dataset(dataset, train=False):\n",
        "  if train:\n",
        "    dataset = dataset.shuffle(num_train_examples)\n",
        "    dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "  dataset = dataset.cache().prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
        "  return dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NzGu2hUKfnA",
        "cellView": "form"
      },
      "source": [
        "#@title \"Utilities [RUN ME]\"\n",
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_len, tokenizer=bert_tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid=None, text_a=text.numpy(), text_b=None, label=label.numpy())\n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list, max_seq_length, tokenizer)\n",
        "\n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)\n",
        "  \n",
        "def to_feature_map(text, label):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp=[text, label], Tout=[tf.int32,tf.int32, tf.int32, tf.int32 ])\n",
        "  input_ids.set_shape([max_seq_len])\n",
        "  segment_ids.set_shape([max_seq_len])\n",
        "  input_mask.set_shape([max_seq_len])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "       'input_word_ids': input_ids,\n",
        "       'input_mask': input_mask,\n",
        "       'input_type_ids':segment_ids\n",
        "  }\n",
        "  \n",
        "  return (x, label_id)\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ADXfSXSIWGpt"
      },
      "source": [
        "#@title \"Utilities [RUN ME]\"\n",
        "def create_model():\n",
        "\n",
        " encoder_inputs = dict(\n",
        "    input_word_ids=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"input_word_ids\"),\n",
        "    input_mask=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,  name=\"input_mask\"),\n",
        "    input_type_ids=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name=\"input_type_ids\"),\n",
        ")\n",
        " \n",
        " net = bert_layer(encoder_inputs)['pooled_output']\n",
        "\n",
        " net = tf.keras.layers.Dropout(0.2)(net)\n",
        " net = tf.keras.layers.Dense(384, activation='ReLU', name='dense_384')(net)\n",
        " net = tf.keras.layers.Dense(192, activation='ReLU', name='dense_192')(net)\n",
        " net = tf.keras.layers.Dense(96, activation='ReLU', name='dense_96')(net)\n",
        " output = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
        "\n",
        " model = tf.keras.Model(\n",
        "     encoder_inputs,\n",
        "     outputs=output,\n",
        "     name='prediction'\n",
        " )\n",
        " return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyRKSP2zwYyo"
      },
      "source": [
        "#Read TFRecord data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFYhIMQxwy6k",
        "outputId": "148e2414-7efe-4f3e-9762-c5f4fded3ec2"
      },
      "source": [
        "#instantiate read_data utility\n",
        "read_data = read_tfrec_data(tfrecFiles_path, VALIDATION_SPLIT=0.2, TESTING_SPLIT=0.2, MODE=1)\n",
        "\n",
        "# splitting data files between training, validation and test\n",
        "filenames, training_filenames, validation_filenames, testing_filenames = read_data.get_tfrec_files()\n",
        "num_train_examples = 500 * len(training_filenames)\n",
        "\n",
        "validation_steps = int(31986  // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(31986  // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
        "\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = num_train_steps // 10\n",
        "\n",
        "print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(BATCH_SIZE, steps_per_epoch, validation_steps))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern matches 64 data files. Splitting dataset into 52 training files , 10 validation files and 2 test files\n",
            "With a batch size of 32, there will be 810 batches per training epoch and 155 batch(es) per validation run.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dexXAe2b0LQl"
      },
      "source": [
        "#Load TFRecord into TF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2YkXiW0Osa"
      },
      "source": [
        "# create the datasets\n",
        "with tf.device('/cpu:0'):\n",
        "  train_ds = load_dataset(training_filenames)\n",
        "  val_ds = load_dataset(validation_filenames)\n",
        "  test_ds = load_dataset(testing_filenames)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81QxcdL40xMi",
        "outputId": "1a428eee-b789-4b0e-934c-de95d5022891"
      },
      "source": [
        "for i,(text, class_num, label) in enumerate(train_ds.take(10)):\n",
        "  print(f\"text : {text.numpy()}, class : {class_num.numpy()}, label : {label.numpy()}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text : b'american singer and actor al martino dies at age', class : 0, label : b'nonclickbaits'\n",
            "text : b'suicide bomber kills at least eight in eastern afghanistan', class : 0, label : b'nonclickbaits'\n",
            "text : b'of our favourite television moments in', class : 1, label : b'clickbaits'\n",
            "text : b'bombings reported in bangkok', class : 0, label : b'nonclickbaits'\n",
            "text : b'us x factor producers confirm line up changes', class : 0, label : b'nonclickbaits'\n",
            "text : b'ad losses put squeeze on tv news', class : 0, label : b'nonclickbaits'\n",
            "text : b'at least killed by hurricane katrina serious flooding across affected region', class : 0, label : b'nonclickbaits'\n",
            "text : b'india announces lok sabha elections for', class : 0, label : b'nonclickbaits'\n",
            "text : b'speedskating provided marsicano a refuge from bullying and depression', class : 0, label : b'nonclickbaits'\n",
            "text : b'belgian ship hijacked off horn of africa by somali pirates', class : 0, label : b'nonclickbaits'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9EYaEqFQKM5"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  train_ds = train_ds.map(lambda text, class_num, label:(text, class_num))\n",
        "  val_ds = val_ds.map(lambda text, class_num, label:(text, class_num))\n",
        "  test_ds = test_ds.map(lambda text, class_num, label:(text, class_num))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4mlvS-W4TDx"
      },
      "source": [
        "#Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-C-yuTZILRE"
      },
      "source": [
        "##Bert preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVTejAUcINXW"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  train_data = train_ds.map(to_feature_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  train_data = get_batched_dataset(train_data, train=True)\n",
        "\n",
        "  # valid\n",
        "  val_data = val_ds.map(to_feature_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  val_data = get_batched_dataset(val_data)\n",
        "\n",
        "  # test\n",
        "  test_data = test_ds.map(to_feature_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  test_data = get_batched_dataset(test_data)\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waCLqUaWSbQY",
        "outputId": "dc472674-93aa-4f04-baf8-aee3d4ccb271"
      },
      "source": [
        "# train data spec\n",
        "train_data.element_spec"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsCwE3RZSi3e"
      },
      "source": [
        "#Build classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHVKiVfzSkSl",
        "outputId": "0d4dd053-38d0-4de9-94f6-595780de5796"
      },
      "source": [
        "classifier_model = create_model()\n",
        "classifier_model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"prediction\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert_encoder (KerasLayer)       {'encoder_outputs':  109482241   input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "                                                                 input_word_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           bert_encoder[0][13]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_384 (Dense)               (None, 384)          295296      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_192 (Dense)               (None, 192)          73920       dense_384[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_96 (Dense)                (None, 96)           18528       dense_192[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 1)            97          dense_96[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 109,870,082\n",
            "Trainable params: 109,870,081\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N59HP--s89aR",
        "outputId": "e27177f6-6b8b-422d-ec1a-164b0041a049"
      },
      "source": [
        "#Load weights if available\n",
        "if os.path.exists(checkpoint_root_path):\n",
        "  print('loading weight')\n",
        "  classifier_model.load_weights(model_checkpoint_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading weight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0DDL0bciiAD"
      },
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                        verbose=1, \n",
        "                                        patience=5, \n",
        "                                        mode='min', \n",
        "                                        restore_best_weights=True)\n",
        "\n",
        "METRICS = [\n",
        "                keras.metrics.TruePositives(name='tp'),\n",
        "                keras.metrics.FalsePositives(name='fp'),\n",
        "                keras.metrics.TrueNegatives(name='tn'),\n",
        "                keras.metrics.FalseNegatives(name='fn'), \n",
        "                keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "                keras.metrics.Precision(name='precision'),\n",
        "                keras.metrics.Recall(name='recall'),\n",
        "                keras.metrics.AUC(name='auc'),\n",
        "                keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "     ]\n",
        "\n",
        "optimizer = optimization.create_optimizer(\n",
        "      init_lr=init_lr,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      optimizer_type='adamw')\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "              metrics=METRICS)\n",
        "\n",
        "#tf.keras.utils.plot_model(model=classifier_model, show_shapes=True, dpi=60)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-l3hSAZjmAR"
      },
      "source": [
        "#Train classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN83npGrjnwd",
        "outputId": "490d5c4c-26c2-4dbd-94e0-4143685a271e"
      },
      "source": [
        "history = classifier_model.fit(\n",
        "      x=train_data,\n",
        "      validation_data=val_data,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      validation_steps=validation_steps,\n",
        "      callbacks=[es])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "810/810 [==============================] - 857s 867ms/step - loss: 0.0027 - tp: 12962.0000 - fp: 5.0000 - tn: 12941.0000 - fn: 12.0000 - accuracy: 0.9993 - precision: 0.9996 - recall: 0.9991 - auc: 0.9998 - prc: 0.9998 - val_loss: 0.0709 - val_tp: 2438.0000 - val_fp: 31.0000 - val_tn: 2456.0000 - val_fn: 35.0000 - val_accuracy: 0.9867 - val_precision: 0.9874 - val_recall: 0.9858 - val_auc: 0.9931 - val_prc: 0.9906\n",
            "Epoch 2/2\n",
            "810/810 [==============================] - 701s 865ms/step - loss: 0.0038 - tp: 12948.0000 - fp: 5.0000 - tn: 12949.0000 - fn: 18.0000 - accuracy: 0.9991 - precision: 0.9996 - recall: 0.9986 - auc: 0.9998 - prc: 0.9998 - val_loss: 0.0709 - val_tp: 2438.0000 - val_fp: 31.0000 - val_tn: 2456.0000 - val_fn: 35.0000 - val_accuracy: 0.9867 - val_precision: 0.9874 - val_recall: 0.9858 - val_auc: 0.9931 - val_prc: 0.9906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq21bsBY5zci"
      },
      "source": [
        "# Save model weights\n",
        "classifier_model.save_weights(model_checkpoint_path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il2faBB5uhbz"
      },
      "source": [
        "#Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82Q5YKoQulNX",
        "outputId": "872ee904-f86c-4010-f1c4-ebbaac6963a4"
      },
      "source": [
        "results = classifier_model.evaluate(test_data)\n",
        "\n",
        "for name, value in zip(classifier_model.metrics_names, results):\n",
        "  print(name, ': ', value)\n",
        "print()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 9s 288ms/step - loss: 0.1108 - tp: 477.0000 - fp: 11.0000 - tn: 496.0000 - fn: 8.0000 - accuracy: 0.9808 - precision: 0.9775 - recall: 0.9835 - auc: 0.9887 - prc: 0.9828\n",
            "loss :  0.11084893345832825\n",
            "tp :  477.0\n",
            "fp :  11.0\n",
            "tn :  496.0\n",
            "fn :  8.0\n",
            "accuracy :  0.9808467626571655\n",
            "precision :  0.9774590134620667\n",
            "recall :  0.983505129814148\n",
            "auc :  0.9886781573295593\n",
            "prc :  0.9828189611434937\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hyxBLmuwTsg"
      },
      "source": [
        "#Export for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ8OWWr6tPvX"
      },
      "source": [
        "classifier_model.save(saved_model_path, include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}